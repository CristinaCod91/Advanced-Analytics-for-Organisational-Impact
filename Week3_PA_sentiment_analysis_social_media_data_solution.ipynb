{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94199fa3",
   "metadata": {},
   "source": [
    "### LSE Data Analytics Online Career Accelerator \n",
    "\n",
    "# DA301:  Advanced Analytics for Organisational Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fcc342",
   "metadata": {},
   "source": [
    "## Practical activity: Pre-processing textural data from social media"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26969258",
   "metadata": {},
   "source": [
    "**This is the solution to the activity.**\n",
    "\n",
    "We will continue working with the data analytics team at Tumble Confectionery. Recall that the product line includes a range of chocolate products in unusual flavour combinations, and the company is using social media to research potential new flavours.\n",
    "\n",
    "The product manager has a hunch that a cheesecake flavour would be a good addition to the product line. You have been asked to research the sentiment towards cheesecake on Twitter. We will look at some tweets about cheesecake straight from Twitter and apply natural language processing steps in order to comprehend the data at scale. Your objective is to:\n",
    "\n",
    "- identify positive and negative sentiments related to cheesecake\n",
    "- use the polarity score function and identify related words\n",
    "- visualise the output to present back to the business to help them decide on adding a flavour to their product line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec3ed0",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "##  Prepare your workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, install the libraries.\n",
    "!pip install pyyaml\n",
    "!pip install twitter\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d529667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the YAML file and your Twitter keys over to this Jupyter Notebook before you start to work.\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from twitter import *\n",
    "import time\n",
    "\n",
    "# Import the yaml file â€“ remember to specify the whole path and use / between directories.\n",
    "twitter_creds = yaml.safe_load(open('twitter.yaml', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f554d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass your Twitter credentials.\n",
    "twitter_api = Twitter(auth=OAuth(twitter_creds['access_token'],\n",
    "                                 twitter_creds['access_token_secret'], \n",
    "                                 twitter_creds['api_key'],\n",
    "                                 twitter_creds['api_secret_key'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b72765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See whether you are connected.\n",
    "print(twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a test with #python.\n",
    "python_tweets = twitter_api.search.tweets(q='#python')\n",
    "\n",
    "# View output.\n",
    "print(python_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a657692",
   "metadata": {},
   "source": [
    "## 1. Test connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f249f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the term cheesecake.\n",
    "q = {'q':'cheesecake', 'count':100, 'result_type':'recent'}\n",
    "results = []\n",
    "\n",
    "while len(results) < 30:\n",
    "    query = twitter_api.search.tweets(**q)\n",
    "    try:\n",
    "        q['max_id'] = query['search_metadata']['next_results'].split('&')[0].split('?max_id=')[1]\n",
    "        results.append(query)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "# Determine the number of results.\n",
    "len(results)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb192e4",
   "metadata": {},
   "source": [
    "## 2. Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec148ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas to join the DataFrames.\n",
    "import pandas as pd\n",
    "\n",
    "# Concat DataFrames.\n",
    "results_list_pd = pd.concat([pd.DataFrame(_['statuses']) for _ in results])\n",
    "\n",
    "# View shape of output.\n",
    "results_list_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e4f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine values of output.\n",
    "results_list_values = results_list_pd['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946755e",
   "metadata": {},
   "source": [
    "## 3. Investigate tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51943af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk and the required resources.\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8684a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at one raw tweet.\n",
    "results_list_values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf683cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up each tweet into individual words.\n",
    "results_list_values_token = [word_tokenize(_) for _ in results_list_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec69a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all English words so we can exclude anything that doesn't appear on the list.\n",
    "all_english_words = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdfb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some pre-processing:\n",
    "#-- Let's get every word.\n",
    "#-- Let's convert it to lowercase.\n",
    "#-- Only include if the word is alphanumeric and if it is in the list of English words.\n",
    "\n",
    "results_list_values_token_nostop =\\\n",
    "[[y.lower() for y in x if y.lower() not in stop_words and y.isalpha() and y.lower() in all_english_words]\\\n",
    " for x in results_list_values_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the same tweet as above.\n",
    "results_list_values_token_nostop[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff7fbce",
   "metadata": {},
   "source": [
    "# NLTK sentiment analysis \n",
    "## 1. Prepare your workstation\n",
    "> Run the previous code snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0698af2",
   "metadata": {},
   "source": [
    "## 2. Import NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the prebuilt rules and values of the vader lexicon.\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c985ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the vader classs and create a object of the analyzer called Darth Vader.\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create a variable to store the sia.\n",
    "darth_vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47326f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through a dictionary comprehension to take every cleaned tweet. \n",
    "# Next run the polarity score function on the string.\n",
    "# This will return four values in a dictionary.\n",
    "\n",
    "results_list_values_token_nostop_polarity =\\\n",
    "{\" \".join(_) : darth_vader.polarity_scores(\" \".join(_)) for _ in results_list_values_token_nostop}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ed7b5",
   "metadata": {},
   "source": [
    "## 3. Create a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionary results to a pandas dataframe. \n",
    "# The index is the cleaned tweet.\n",
    "# We can see some of the highly positive words. \n",
    "\n",
    "polarity_pd = pd.DataFrame(results_list_values_token_nostop_polarity).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3059cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the non-aplhanumeric words (the emojis, handles, hashtags and stopwords) removed \n",
    "# some of the most positive words are single words.\n",
    "\n",
    "# Get the top five most positive cleaned tweets related to cheesecake.\n",
    "polarity_pd.sort_values('pos', ascending=0).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde71e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top five most negative words related to cheesecake.\n",
    "polarity_pd.sort_values('neg', ascending=0).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95114767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe function on the compound will show the distribution and moments. \n",
    "# The average is 0.1 so slightly positive.\n",
    "polarity_pd['compound'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0152065b",
   "metadata": {},
   "source": [
    "## 3. Plot the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e133b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes the best way to see is to plot. \n",
    "# In the data sampled here many of the values are 0.\n",
    "# There are fewer negative values than positive ones, but the negative values are highly negative.\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_plot = polarity_pd.reset_index()['compound'].sort_values()\n",
    "_plot.plot(kind='bar')\n",
    "ax1 = plt.axes()\n",
    "x_axis = ax1.axes.get_xaxis()\n",
    "x_axis.set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e85e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The boxplot is a nice way to see how many values sit on the edges as outliers.\n",
    "_plot = polarity_pd.reset_index()['compound'].sort_values()\n",
    "_plot.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40345496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
